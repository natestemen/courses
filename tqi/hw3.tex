\documentclass[boxes,pages,color=SeaGreen]{homework}

\hypersetup{
    colorlinks=true,
    urlcolor=SeaGreen!60!black,
    linkcolor=Bittersweet
}
\newcommand{\collab}[1]{\footnote{\href{mailto:#1}{\texttt{#1}}}}

\name{Nate Stemen}
\studentid{20906566}
\email{nate@stemen.email}
\term{Fall 2021}
\course{Theory of Quantum Information}
\courseid{QIC 820}
\hwnum{3}
\duedate{Nov 23, 2021}

\hwname{Assignment}

\usepackage{physics}
\usepackage{macros}
\usepackage{cleveref}

%-----------------------------------------------------------------------------%
% Macros
%-----------------------------------------------------------------------------%

\newcommand{\tinyspace}{\mspace{1mu}}
\renewcommand{\vec}{\operatorname{vec}}
\renewcommand{\op}[1]{\operatorname{#1}}

\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\U}{\mathcal{U}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\Fid}{\operatorname{F}}
\newcommand{\reg}[1]{\mathsf{#1}}
\newcommand{\ent}{\operatorname{H}}
\newcommand{\mutIn}[2]{\operatorname{I}(#1 : #2)}
\newcommand{\smalltag}[1]{\tag*{\footnotesize (#1)}}

\newcommand{\Lin}{\mathrm{L}}
\newcommand{\Trans}{\mathrm{T}}
\newcommand{\Pos}{\mathrm{Pos}}
\newcommand{\Herm}{\mathrm{Herm}}
\newcommand{\Channel}{\mathrm{C}}
\newcommand{\Unitary}{\mathrm{U}}
\newcommand{\Density}{\mathrm{D}}
\newcommand{\CP}{\mathrm{CP}}
\newcommand{\relEn}{\mathrm{D}}

\newcommand{\triplenorm}[1]{
  \lvert\!\lvert\!\lvert #1 
  \rvert\!\rvert\!\rvert}


\begin{document}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$, $\reg{Y}$ and $\reg{Z}$ be registers.
Prove that, for any state of these registers, the following two inequalities
are true:
\begin{parts}
    \part
    $\op{I}(\reg{X},\reg{Y} : \reg{Z}) +
        \op{I}(\reg{Y} : \reg{Z}) \geq \op{I}(\reg{X} : \reg{Z})$.\label{part:1a}
    \part
    $\op{I}(\reg{X},\reg{Y} : \reg{Z})
        \leq \op{I}(\reg{Y}:\reg{X},\reg{Z}) + 2\op{H}(\reg{X})$.\label{part:1b}
\end{parts}
\end{problem}

\begin{solution}
    \ref{part:1a}
    First note that the mutual information is symmetric in it's arguments.
    This property is inherited from the symmetry of the von Neumann entropy for a compound register.
    \begin{equation*}
        \mutIn{\reg{X}}{\reg{Y}} = \ent(\reg{X}) + \ent(\reg{Y}) - \ent(\reg{X}, \reg{Y}) =  \ent(\reg{Y}) + \ent(\reg{X}) - \ent(\reg{Y}, \reg{X}) = \mutIn{\reg{Y}}{\reg{X}}
    \end{equation*}
    Corollary 5.37 tells us that $\mutIn{\reg{X}}{\reg{Z}} \leq \mutIn{\reg{X}}{\reg{Y},\reg{Z}}$, and hence all we need to show is $\mutIn{\reg{Y}}{\reg{Z}} \geq 0$.
    By the subadditivity of the von Neumann entropy we have $\ent(\reg{Y}, \reg{Z}) \leq \ent(\reg{Y}) + \ent(\reg{Z})$ and hence
    \begin{align*}
        \ent(\reg{Y}) + \ent(\reg{Z})                          & \geq \ent(\reg{Y}, \reg{Z}) \\
        \ent(\reg{Y}) + \ent(\reg{Z}) - \ent(\reg{Y}, \reg{Z}) & \geq 0                      \\
        \mutIn{\reg{Y}}{\reg{Z}}                               & \geq 0.
    \end{align*}
    This fact, together with Corollary 5.37 Proves \ref{part:1a}.

    \ref{part:1b}
    In this part we use both the subadditivity of the von Neumann entropy, together with Theorem 5.25 which states $\ent(\reg{X}) \leq \ent(\reg{Y}) + \ent(\reg{X}, \reg{Y})$.
    \begin{align*}
        \mutIn{\reg{X}, \reg{Y}}{\reg{Z}} & \defeq \ent(\reg{X}, \reg{Y}) + \ent(\reg{Z}) - \ent(\reg{X}, \reg{Y}, \reg{Z})                                                         \\
                                          & \leq \ent(\reg{X}) + \ent(\reg{Y}) + \ent(\reg{Z}) - \ent(\reg{X}, \reg{Y}, \reg{Z}) \smalltag{subadditivity}                           \\
                                          & \leq \ent(\reg{X}) + \ent(\reg{Y}) + \qty\Big[\ent(\reg{X}) + \ent(\reg{X}, \reg{Z})] - \ent(\reg{X}, \reg{Y}, \reg{Z}) \smalltag{5.25} \\
                                          & = \ent(\reg{Y}) + \ent(\reg{X}, \reg{Z}) - \ent(\reg{Y}, \reg{X}, \reg{Z}) + 2\ent(\reg{X}) \smalltag{symmetry of $\ent$}               \\
                                          & = \mutIn{\reg{Y}}{\reg{X},\reg{Z}} + 2\ent(\reg{X})
    \end{align*}
    So there we go.
\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\X$ be a complex Euclidean space,
let $\Sigma$ be an alphabet,
let $p\in\P(\Sigma)$ be a probability vector, and
let $\{\rho_a\,:\,a\in\Sigma\}\subseteq\Density(\X)$ be a collection of
states.
Prove that, for every state $\sigma\in\Density(\X)$, we have
\[
    \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \sigma)
    = \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \rho) +
    \mathrm{D}(\rho \| \sigma),
\]
where
\[
    \rho = \sum_{a\in\Sigma} p(a) \rho_a.
\]
\end{problem}

\begin{solution}
    By the linearity of the trace we have
    \begin{align*}
        \relEn(\rho \| \sigma) = \tr(\rho\log\rho) - \tr(\rho\log\sigma) = \sum_{a\in\Sigma}p(a)\qty\big[\tr(\rho_a\log\rho) - \tr(\rho_a\log\sigma)].
    \end{align*} % TODO
    Thus the left hand side of the equation to be proven is finite when $\im(\rho_a) \subseteq \im(\rho)$ which is always true given the form of $\rho$, and $\im(\rho_a) \subseteq \im(\sigma)$. Given that holds for each $a \in \Sigma$, then it must also hold for a convex combination of them, and hence $\im(\rho) \subseteq \im(\sigma)$.
    This implies that when the left hand side is finite, so is the right hand side, and the reasoning can be run in reverse to show both sides are infinite when $\mathrm{D}(\rho_a \| \sigma)$ is infinite.

    Now we can address the equality when both sides are finite.
    \begin{align*}
        \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \rho) & + \mathrm{D}(\rho \| \sigma)                                                                                                  \\
                                                          & \defeq \sum_{a\in\Sigma} p(a) \qty\Big[\tr(\rho_a\log\rho_a) - \tr(\rho_a\log\rho)] + \tr(\rho\log\rho) - \tr(\rho\log\sigma) \\
                                                          & = \sum_{a\in\Sigma} p(a) \tr(\rho_a\log\rho_a) - \tr(\rho\log\rho) + \tr(\rho\log\rho) - \tr(\rho\log\sigma)                  \\
                                                          & = \sum_{a\in\Sigma} p(a) \tr(\rho_a\log\rho_a) - \tr(\rho\log\sigma)                                                          \\
                                                          & = \sum_{a\in\Sigma} p(a) \qty\Big[\tr(\rho_a\log\rho_a) - \tr(\rho_a\log\sigma)]                                              \\
                                                          & \eqdef \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \sigma)
    \end{align*}

\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$ and $\reg{Y}$ be registers, let $\Sigma$ be an alphabet,
let $p\in\P(\Sigma)$ be a probability vector, let
$\{\sigma_a : a\in\Sigma\}\subseteq\Density(\X)$ and
$\{\xi_a : a\in\Sigma\}\subseteq\Density(\Y)$ be collections of density
operators, and define $\rho\in\Density(\X\otimes\Y)$ as
\begin{equation*}
    \rho = \sum_{a\in\Sigma} p(a)\tinyspace\sigma_a\otimes\xi_a.
\end{equation*}
States that can be expressed in this way are called \emph{separable states},
and will be discussed in the fourth part of the course---but nothing from
that part of the course is needed to solve this problem.

\begin{parts}
    \part
    Prove that
    $\op{I}(\reg{X} : \reg{Y})_{\rho} \leq \op{H}(p)$.\label{part:3a}
    \part
    Prove that
    \[
        \op{H}(\rho) \geq \sum_{a\in\Sigma} p(a) \op{H}(\sigma_a)
        + \op{H}\qty(\sum_{a\in\Sigma} p(a)\tinyspace\xi_a).
    \]\label{part:3b}
\end{parts}
\end{problem}

\noindent Solution completed in collaboration with Mohammad Ayyash,\collab{mmayyash@uwaterloo.ca} and Nicholas Zutt.\collab{nzutt@uwaterloo.ca}

{\noindent\color{SeaGreen!30}\rule{\textwidth}{1.5pt}}

\begin{solution}
    \ref{part:3a}
    By the definition of mutual information we have $\op{I}(\reg{X} : \reg{Y}) \defeq \ent(\reg{X}) + \ent(\reg{Y}) - \ent(\reg{X}, \reg{Y})$ and the fact we are making this calculation with respect to $\rho$ we have $\ent(\reg{X}, \reg{Y}) = \ent(\rho)$.
    We can then write the mutual information as $\op{I}(\reg{X} : \reg{Y}) = \ent(\rho[X]) = \ent(\rho[Y]) - \ent(\rho)$.

    Let's now spectral decompose each $\sigma_a$ as $\sigma_a = \sum_{b\in\Gamma} \lambda_{ab}\ketbra{\psi_{ab}}$ where we've taken $\X = \C^\Gamma$.
    We can now calculate the associated terms of $\op{I}(\reg{X} : \reg{Y})$.
    Here we use a fact that $\ent(\sum_{a \in \Sigma} p(a) \rho_a) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\rho_a)$ for $p\in\mathcal{P}(\Sigma)$ and $\rho_a$ density operators.
    To see a proof of such fact, please see my collaborators Nicholas Zutt's write up.
    \begin{align*}
        \ent(\rho[X]) & = \ent\!\qty(\sum_{a \in \Sigma} p(a) \sigma_a) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\sigma_a) \\
        \ent(\rho[Y]) & = \ent\!\qty(\sum_{a \in \Sigma} p(a) \xi_a)    \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\xi_a)
    \end{align*}
    Finally for the last term we have
    \begin{align*}
        \ent(\rho) & = \ent\!\qty(\sum_{\substack{a \in \Sigma                                                                                                  \\ b \in \Gamma}} p(a) \lambda_{ab} \ketbra{\psi_{ab}} \otimes \xi_a) \\
                   & \geq \sum_{a \in \Sigma} p(a) \ent\!\qty(\sum_{b \in \Gamma} \lambda_{ab}\ketbra{\psi_{ab}} \otimes \xi_a) \tag*{\footnotesize(Concavity)} \\
                   & = \sum_{a,b} p(a) \ent\!\qty(\lambda_{ab} \xi_a).
    \end{align*}
    We can now use Equation 5.98 in the book which states $\ent(\alpha P) = \alpha\ent(P) - \alpha\log(\alpha)\tr(P)$ to pull the constants out.
    \begin{align*}
        \sum_{a,b} p(a) \ent\!\qty(\lambda_{ab} \xi_a) & = \sum_{a,b} p(a) \lambda_{ab}\ent(\xi_a) - p(a) \lambda_{ab}\log(p(a)\lambda_{ab})\tr(\xi_a)                                                                                                           \\
                                                       & = \sum_{a,\colorbox{SeaGreen!30}{\footnotesize$b$}} p(a) \colorbox{SeaGreen!30}{$\lambda_{ab}$}\ent(\xi_a) - p(a) \colorbox{SeaGreen!30}{$\lambda_{ab}$}\log(p(a)) - p(a)\lambda_{ab}\log(\lambda_{ab})
    \end{align*}
    The highlighted terms vanish (with the sum on $b$) because $\tr(\sigma_a) = \sum_b \lambda_{ab} = 1$.
    \begin{align*}
        \ent(\rho) & \geq \sum_{a \in \Sigma} p(a) \ent(\xi_a) - p(a) \log(p(a)) - p(a)\sum_{b} \lambda_{ab} \log(\lambda_{ab}) \\
                   & = \sum_{a \in \Sigma} p(a)\ent(\xi_a) + \ent(p) + p(a)\ent(\sigma_a)
    \end{align*}
    We can now put together all of the terms as follows.
    \begin{align*}
        \op{I}(\reg{X} : \reg{Y})_\rho & \defeq \ent(\rho[X]) + \ent(\rho[Y]) - \ent(\rho)                                                                  \\
                                       & \leq \ent(p) + \qty[\sum_{a \in \Sigma} p(a)\ent(\sigma_a)] + \ent(p) + \qty[\sum_{a \in \Sigma} p(a) \ent(\xi_a)] \\
                                       & \qquad \qquad - \ent(p) - \sum_{a \in \Sigma} p(a)\ent(\xi_a) + p(a)\ent(\sigma_a)                                 \\
                                       & = \ent(p)
    \end{align*}

    \ref{part:3b}
    In the previous part we showed
    \begin{equation*}
        \ent(\rho) = \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\xi_a) + p(a)\ent(\sigma_a)
    \end{equation*}
    and hence to show $\ent(\rho) \geq \sum_{a \in \Sigma} p(a)\ent(\sigma_a) + \ent\!\qty\big(\sum_{a \in \Sigma} p(a) \xi_a)$ we must prove
    \begin{equation*}
        \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\xi_a) \geq \ent\qty(\sum_{a \in \Sigma} p(a) \xi_a)
    \end{equation*}
    which we prove in problem 4.
\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$ be a register having alphabet $\Sigma$, and also let
$\reg{Y}$ and $\reg{Z}$ be registers (having arbitrary alphabets we need
not name).
Let $\{\sigma_a\,:\,a\in\Sigma\}\subseteq\Density(\Y\otimes\Z)$
be a collection of density operators, let $p\in\P(\Sigma)$ be a probability
vector, and define $\rho\in\Density(\X\otimes\Y\otimes\Z)$ as
\[
    \rho = \sum_{a\in\Sigma} p(a) \ketbra{a} \otimes \sigma_a.
\]
Prove that, with respect to the state $\rho$, one has
\[
    \op{I}(\reg{X},\reg{Y} : \reg{Z})
    \leq \op{I}(\reg{Y}:\reg{X},\reg{Z}) + \op{H}(\reg{X}).
\]
\end{problem}

\noindent Solution completed in collaboration with Margie Christ.\collab{mchrist@uwaterloo.ca}

{\noindent\color{SeaGreen!30}\rule{\textwidth}{1.5pt}}

\end{document}
