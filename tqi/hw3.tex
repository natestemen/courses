\documentclass[boxes,pages,color=SeaGreen]{homework}

\hypersetup{
    colorlinks=true,
    urlcolor=SeaGreen!60!black,
    linkcolor=Bittersweet
}
\newcommand{\collab}[1]{\footnote{\href{mailto:#1}{\texttt{#1}}}}

\name{Nate Stemen}
\studentid{20906566}
\email{nate@stemen.email}
\term{Fall 2021}
\course{Theory of Quantum Information}
\courseid{QIC 820}
\hwnum{3}
\duedate{Nov 26, 2021}

\hwname{Assignment}

\usepackage{physics}
\usepackage{macros}
\usepackage{cleveref}

%-----------------------------------------------------------------------------%
% Macros
%-----------------------------------------------------------------------------%

% \theoremstyle{definition}
\newtheorem*{fact}{Fact}

\newcommand{\tinyspace}{\mspace{1mu}}
\renewcommand{\op}[1]{\operatorname{#1}}

\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Z}{\mathcal{Z}}
\newcommand{\W}{\mathcal{W}}
\newcommand{\V}{\mathcal{V}}
\newcommand{\U}{\mathcal{U}}
\renewcommand{\P}{\mathcal{P}}
\newcommand{\reg}[1]{\mathsf{#1}}
\newcommand{\ent}{\operatorname{H}}
\newcommand{\mutIn}[2]{\operatorname{I} (#1: #2)}
\newcommand{\smalltag}[1]{\tag*{\footnotesize (#1)}}

\newcommand{\Pos}{\mathrm{Pos}}
\newcommand{\Density}{\mathrm{D}}
\newcommand{\relEn}{\mathrm{D}}


\begin{document}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$, $\reg{Y}$ and $\reg{Z}$ be registers.
Prove that, for any state of these registers, the following two inequalities
are true:
\begin{parts}
    \part
    $\op{I}(\reg{X},\reg{Y} : \reg{Z}) +
        \op{I}(\reg{Y} : \reg{Z}) \geq \op{I}(\reg{X} : \reg{Z})$.\label{part:1a}
    \part
    $\op{I}(\reg{X},\reg{Y} : \reg{Z})
        \leq \op{I}(\reg{Y}:\reg{X},\reg{Z}) + 2\op{H}(\reg{X})$.\label{part:1b}
\end{parts}
\end{problem}

\begin{solution}
    \ref{part:1a}
    First note that the mutual information is symmetric with respect to it's arguments.
    This property is inherited from the symmetry of the von Neumann entropy for a compound register: $\ent(\reg{X}, \reg{Y}) = \ent(\reg{Y}, \reg{X})$.
    \begin{equation*}
        \mutIn{\reg{X}}{\reg{Y}} = \ent(\reg{X}) + \ent(\reg{Y}) - \ent(\reg{X}, \reg{Y}) =  \ent(\reg{Y}) + \ent(\reg{X}) - \ent(\reg{Y}, \reg{X}) = \mutIn{\reg{Y}}{\reg{X}}
    \end{equation*}
    We also have the ability to permute registers inside either argument to the mutual information.
    \begin{equation*}
        \mutIn{\reg{X}}{\reg{Y}, \reg{Z}} = \ent(\reg{X}) + \ent(\reg{Y}, \reg{Z}) - \ent(\reg{X}, \reg{Y}, \reg{Z}) = \ent(\reg{X}) + \ent(\reg{Z}, \reg{Y}) - \ent(\reg{X}, \reg{Z}, \reg{Y}) = \mutIn{\reg{X}}{\reg{Z}, \reg{Y}}
    \end{equation*}
    Using these properties along with corollary 5.37 which says $\mutIn{\reg{A}}{\reg{B},\reg{C}} \geq \mutIn{\reg{A}}{\reg{C}}$ we have the following manipulation.
    \begin{align*}
        \mutIn{\reg{X}, \reg{Y}}{\reg{Z}} = \mutIn{\reg{Z}}{\reg{X}, \reg{Y}} = \mutIn{\reg{Z}}{\reg{Y}, \reg{X}} \geq \mutIn{\reg{Z}}{\reg{X}} = \mutIn{\reg{X}}{\reg{Z}}
    \end{align*}
    To complete the proof of the desired inequality, we now need to show $\mutIn{\reg{Y}}{\reg{Z}} \geq 0$ which follows from the subadditivity of the von Neumann entropy.
    \begin{align*}
        \ent(\reg{Y}) + \ent(\reg{Z})                          & \geq \ent(\reg{Y}, \reg{Z}) \\
        \ent(\reg{Y}) + \ent(\reg{Z}) - \ent(\reg{Y}, \reg{Z}) & \geq 0                      \\
        \mutIn{\reg{Y}}{\reg{Z}}                               & \geq 0.
    \end{align*}
    This completes the proof.

    \ref{part:1b}
    In this part we use both the subadditivity of the von Neumann entropy, together with Theorem 5.25 which states $\ent(\reg{X}) \leq \ent(\reg{Y}) + \ent(\reg{X}, \reg{Y})$.
    \begin{align*}
        \mutIn{\reg{X}, \reg{Y}}{\reg{Z}} & \defeq \ent(\reg{X}, \reg{Y}) + \ent(\reg{Z}) - \ent(\reg{X}, \reg{Y}, \reg{Z})                                                         \\
                                          & \leq \ent(\reg{X}) + \ent(\reg{Y}) + \ent(\reg{Z}) - \ent(\reg{X}, \reg{Y}, \reg{Z}) \smalltag{subadditivity}                           \\
                                          & \leq \ent(\reg{X}) + \ent(\reg{Y}) + \qty\Big[\ent(\reg{X}) + \ent(\reg{X}, \reg{Z})] - \ent(\reg{X}, \reg{Y}, \reg{Z}) \smalltag{5.25} \\
                                          & = \ent(\reg{Y}) + \ent(\reg{X}, \reg{Z}) - \ent(\reg{Y}, \reg{X}, \reg{Z}) + 2\ent(\reg{X}) \smalltag{symmetry of $\ent$}               \\
                                          & = \mutIn{\reg{Y}}{\reg{X},\reg{Z}} + 2\ent(\reg{X})
    \end{align*}
    So there we go.
\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\X$ be a complex Euclidean space,
let $\Sigma$ be an alphabet,
let $p\in\P(\Sigma)$ be a probability vector, and
let $\{\rho_a\,:\,a\in\Sigma\}\subseteq\Density(\X)$ be a collection of
states.
Prove that, for every state $\sigma\in\Density(\X)$, we have
\[
    \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \sigma)
    = \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \rho) +
    \mathrm{D}(\rho \| \sigma),
\]
where
\[
    \rho = \sum_{a\in\Sigma} p(a) \rho_a.
\]
\end{problem}

\begin{solution}
    By the linearity of the trace we have
    \begin{align*}
        \relEn(\rho \| \sigma) = \tr(\rho\log\rho) - \tr(\rho\log\sigma) = \sum_{a\in\Sigma}p(a)\qty\big[\tr(\rho_a\log\rho) - \tr(\rho_a\log\sigma)].
    \end{align*} % TODO
    Thus the left hand side of the equation to be proven is finite when $\im(\rho_a) \subseteq \im(\rho)$ which is always true given the form of $\rho$, and $\im(\rho_a) \subseteq \im(\sigma)$.
    Given that holds for each $a \in \Sigma$, then it must also hold for a convex combination of them, and hence $\im(\rho) \subseteq \im(\sigma)$.
    This implies that when the left hand side is finite, so is the right hand side, and the reasoning can be run in reverse to show both sides are infinite when $\mathrm{D}(\rho_a \| \sigma)$ is infinite.

    Now we can address the equality when both sides are finite.
    \begin{align*}
        \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \rho) & + \mathrm{D}(\rho \| \sigma)                                                                                                  \\
                                                          & \defeq \sum_{a\in\Sigma} p(a) \qty\Big[\tr(\rho_a\log\rho_a) - \tr(\rho_a\log\rho)] + \tr(\rho\log\rho) - \tr(\rho\log\sigma) \\
                                                          & = \sum_{a\in\Sigma} p(a) \tr(\rho_a\log\rho_a) - \tr(\rho\log\rho) + \tr(\rho\log\rho) - \tr(\rho\log\sigma)                  \\
                                                          & = \sum_{a\in\Sigma} p(a) \tr(\rho_a\log\rho_a) - \tr(\rho\log\sigma)                                                          \\
                                                          & = \sum_{a\in\Sigma} p(a) \qty\Big[\tr(\rho_a\log\rho_a) - \tr(\rho_a\log\sigma)]                                              \\
                                                          & \eqdef \sum_{a\in\Sigma} p(a) \mathrm{D}(\rho_a \| \sigma)
    \end{align*}

\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$ and $\reg{Y}$ be registers, let $\Sigma$ be an alphabet,
let $p\in\P(\Sigma)$ be a probability vector, let
$\{\sigma_a : a\in\Sigma\}\subseteq\Density(\X)$ and
$\{\xi_a : a\in\Sigma\}\subseteq\Density(\Y)$ be collections of density
operators, and define $\rho\in\Density(\X\otimes\Y)$ as
\begin{equation*}
    \rho = \sum_{a\in\Sigma} p(a)\tinyspace\sigma_a\otimes\xi_a.
\end{equation*}
States that can be expressed in this way are called \emph{separable states},
and will be discussed in the fourth part of the course---but nothing from
that part of the course is needed to solve this problem.

\begin{parts}
    \part
    Prove that
    $\op{I}(\reg{X} : \reg{Y})_{\rho} \leq \op{H}(p)$.\label{part:3a}
    \part
    Prove that
    \[
        \op{H}(\rho) \geq \sum_{a\in\Sigma} p(a) \op{H}(\sigma_a)
        + \op{H}\qty(\sum_{a\in\Sigma} p(a)\tinyspace\xi_a).
    \]\label{part:3b}
\end{parts}
\end{problem}

\noindent Solution completed in collaboration with Mohammad Ayyash,\collab{mmayyash@uwaterloo.ca} and Nicholas Zutt.\collab{nzutt@uwaterloo.ca}

{\noindent\color{SeaGreen!30}\rule{\textwidth}{1.5pt}}

\begin{solution}
    \ref{part:3a}
    By the definition of mutual information we have $\op{I}(\reg{X} : \reg{Y}) \defeq \ent(\reg{X}) + \ent(\reg{Y}) - \ent(\reg{X}, \reg{Y})$ and the fact we are making this calculation with respect to $\rho$ we have $\ent(\reg{X}, \reg{Y}) = \ent(\rho)$.
    We can then write the mutual information as $\op{I}(\reg{X} : \reg{Y}) = \ent(\rho[X]) = \ent(\rho[Y]) - \ent(\rho)$.

    Let's now spectral decompose each $\sigma_a$ as $\sigma_a = \sum_{b\in\Gamma} \lambda_{ab}\ketbra{\psi_{ab}}$ where we've taken $\X = \C^\Gamma$.
    We can now calculate the associated terms of $\op{I}(\reg{X} : \reg{Y})$.
    Here we use a fact that $\ent(\sum_{a \in \Sigma} p(a) \rho_a) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\rho_a)$ for $p\in\P(\Sigma)$ and $\rho_a$ density operators.
    This fact is formalized in the following theorem from Nielsen \& Chuang's \emph{Quantum Computation and Quantum Information} in Theorem 11.10.
    I've taken the liberty to formulate the theorem from their book into the language and notation of this course, as well as omit some unnecessary information.
    \begin{fact}[Theorem 11.10 Neilsen \& Chuang]
        Take $\Sigma$ to be an alphabet, $p \in \P(\Sigma)$ a probability vector, and $\qty{\rho_a : a \in \Sigma} \subseteq \Density(\X)$ a collection of density operators for some complex Euclidean space $\X$.
        If $\rho \defeq \sum_{a \in \Sigma} p(a)\rho_a$ is a convex combination of density operators, then
        \begin{equation*}
            \ent(\rho) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\rho_a).
        \end{equation*}
    \end{fact}
    Using this we then have
    \begin{align*}
        \ent(\rho[X]) & = \ent\!\qty(\sum_{a \in \Sigma} p(a) \sigma_a) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\sigma_a), \\
        \ent(\rho[Y]) & = \ent\!\qty(\sum_{a \in \Sigma} p(a) \xi_a)    \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\xi_a).
    \end{align*}
    Finally for the last term we have
    \begin{align*}
        \ent(\rho) & = \ent\!\qty(\sum_{\substack{a \in \Sigma                                                                                                  \\ b \in \Gamma}} p(a) \lambda_{ab} \ketbra{\psi_{ab}} \otimes \xi_a) \\
                   & \geq \sum_{a \in \Sigma} p(a) \ent\!\qty(\sum_{b \in \Gamma} \lambda_{ab}\ketbra{\psi_{ab}} \otimes \xi_a) \tag*{\footnotesize(Concavity)} \\
                   & = \sum_{a,b} p(a) \ent\!\qty(\lambda_{ab} \xi_a).
    \end{align*}
    We can now use Equation 5.98 in the book which states $\ent(\alpha P) = \alpha\ent(P) - \alpha\log(\alpha)\tr(P)$ to pull the constants out.
    \begin{align*}
        \sum_{a,b} p(a) \ent\!\qty(\lambda_{ab} \xi_a) & = \sum_{a,b} p(a) \lambda_{ab}\ent(\xi_a) - p(a) \lambda_{ab}\log(p(a)\lambda_{ab})\tr(\xi_a)                                                                                                           \\
                                                       & = \sum_{a,\colorbox{SeaGreen!30}{\footnotesize$b$}} p(a) \colorbox{SeaGreen!30}{$\lambda_{ab}$}\ent(\xi_a) - p(a) \colorbox{SeaGreen!30}{$\lambda_{ab}$}\log(p(a)) - p(a)\lambda_{ab}\log(\lambda_{ab})
    \end{align*}
    The highlighted terms vanish (with the sum on $b$) because $\tr(\sigma_a) = \sum_b \lambda_{ab} = 1$.
    \begin{align*}
        \ent(\rho) & \geq \sum_{a \in \Sigma} p(a) \ent(\xi_a) - p(a) \log(p(a)) - p(a)\sum_{b} \lambda_{ab} \log(\lambda_{ab}) \\
                   & = \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\xi_a) + p(a)\ent(\sigma_a)
    \end{align*}
    We can now put together all of the terms as follows.
    \begin{align*}
        \op{I}(\reg{X} : \reg{Y})_\rho & \defeq \ent(\rho[X]) + \ent(\rho[Y]) - \ent(\rho)                                                                                                               \\
                                       & \leq 2\ent(p) + \qty[\sum_{a \in \Sigma} p(a)\qty\Big(\ent(\sigma_a) + \ent(\xi_a))] - \ent(p) - \sum_{a \in \Sigma} p(a)\qty\Big(\ent(\xi_a) + \ent(\sigma_a)) \\
                                       & = \ent(p)
    \end{align*}

    \ref{part:3b}
    In the previous part we showed
    \begin{equation*}
        \ent(\rho) \geq \ent(p) + \sum_{a \in \Sigma} p(a)\qty\Big(\ent(\xi_a) + \ent(\sigma_a))
    \end{equation*}
    and hence to show $\ent(\rho) \geq \sum_{a \in \Sigma} p(a)\ent(\sigma_a) + \ent\!\qty\big(\sum_{a \in \Sigma} p(a) \xi_a)$ we can prove
    \begin{equation*}
        \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\xi_a) \geq \ent\!\qty(\sum_{a \in \Sigma} p(a) \xi_a)
    \end{equation*}
    which is exactly the same fact we used above with $\rho_a = \xi_a$.
\end{solution}

%-----------------------------------------------------------------------------%

\begin{problem}
Let $\reg{X}$ be a register having alphabet $\Sigma$, and also let
$\reg{Y}$ and $\reg{Z}$ be registers (having arbitrary alphabets we need
not name).
Let $\qty{\sigma_a : a \in \Sigma} \subseteq \Density(\Y\otimes\Z)$
be a collection of density operators, let $p \in \P(\Sigma)$ be a probability
vector, and define $\rho \in \Density(\X \otimes \Y \otimes \Z)$ as
\[
    \rho = \sum_{a \in \Sigma} p(a) \ketbra{a} \otimes \sigma_a.
\]
Prove that, with respect to the state $\rho$, one has
\[
    \op{I}(\reg{X},\reg{Y} : \reg{Z})
    \leq \op{I}(\reg{Y} : \reg{X}, \reg{Z}) + \op{H}(\reg{X}).
\]
\end{problem}

\noindent Solution completed in collaboration with Margie Christ.\collab{mchrist@uwaterloo.ca}

{\noindent\color{SeaGreen!30}\rule{\textwidth}{1.5pt}}

\begin{solution}
    To prove this inequality we will first calculate the needed entropies.
    \begin{align*}
        \ent(\reg{X})          & = \ent(\rho[\reg{X}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a)\ketbra{a}) = \ent(p)                                                                         \\
        \ent(\reg{Y})          & = \ent(\rho[\reg{Y}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a)\tr(\ketbra{a})\otimes \tr_\Z\sigma_a) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \tr_\Z \sigma_a) \\
        \ent(\reg{Z})          & = \ent(\rho[\reg{Z}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a)\tr(\ketbra{a})\otimes \tr_\Y\sigma_a) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \tr_\Y \sigma_a) \\
        \ent(\reg{X}, \reg{Y}) & = \ent(\rho[\reg{X}, \reg{Y}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \ketbra{a}\otimes \tr_\Z\sigma_a)                                                   \\
                               & = \sum_{a \in \Sigma}\ent(p(a) \tr_\Z\sigma_a)           \smalltag{Block diagonal form of $\ketbra{a}\otimes\tr_\Z\sigma_a$}                             \\
                               & = \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Z\sigma_a) \smalltag{$\ent(\alpha P) = \alpha \ent(P) - \alpha \log\alpha \tr(P)$}                         \\
        \ent(\reg{X}, \reg{Z}) & = \ent(\rho[\reg{X}, \reg{Z}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \ketbra{a}\otimes \tr_\Y\sigma_a)                                                   \\
                               & = \sum_{a \in \Sigma}\ent(p(a) \tr_\Y\sigma_a)                                                                                                           \\
                               & = \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a)                                                                                                 \\
        \ent(\reg{Y}, \reg{Z}) & = \ent(\rho[\reg{Y}, \reg{Z}]) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \sigma_a)
        % \ent(\reg{X}, \reg{Y}, \reg{Z}) & = \ent(\rho) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \ketbra{a} \otimes \sigma_a) = \ent\!\qty(\sum_{a \in \Sigma} p(a) \sigma_a) = \ent(\reg{Y}, \reg{Z})
    \end{align*}
    We can cancel out the $\ent(\reg{X}, \reg{Y}, \reg{Z})$ term from both sides of our desired inequality to get
    \begin{equation*}
        \ent(\reg{X}, \reg{Y}) + \ent(\reg{Z}) \leq \ent(\reg{Y}) + \ent(\reg{X}, \reg{Z}) + \ent(\reg{X}).
    \end{equation*}
    Starting on the right hand side and using the above calculated entropies we have
    \begin{align*}
        \ent(\reg{Y}) + \ent(\reg{X}, \reg{Z}) + \ent(\reg{X}) & = \ent\!\qty(\sum_{a \in \Sigma} p(a)\tr_\Z\sigma_a) + \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a) + \ent(p) \\
                                                               & = \ent(\reg{Y}) + 2\ent(\reg{X}) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a)                                         \\
                                                               & \geq \ent(\reg{X}) + \ent(\reg{X}, \reg{Y}) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a) \smalltag{subadditivity}
    \end{align*}
    Since $\ent(\reg{X}, \reg{Y})$ appears on both sides, we can cancel the term and it will suffice to show that $\ent(\reg{X}) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a) \geq \ent(\reg{Z})$.
    Expressed slightly differently we have
    \begin{equation*}
        \ent(p) + \sum_{a \in \Sigma} p(a)\ent(\tr_\Y\sigma_a) \geq \ent\!\qty(\sum_{a \in \Sigma} p(a) \tr_\Y\sigma_a).
    \end{equation*}
    Which is an immediate consequence of the following theorem from Nielsen \& Chuang with $\rho_a = \tr_\Y\sigma_a$.
    I've taken the liberty to formulate the theorem from their book into the language and notation of this course, as well as omit some unnecessary information.
    \begin{fact}[Theorem 11.10 Neilsen \& Chuang]
        Take $\Sigma$ to be an alphabet, $p \in \P(\Sigma)$ a probability vector, and $\qty{\rho_a : a \in \Sigma} \subseteq \Density(\X)$ a collection of density operators for some complex Euclidean space $\X$.
        If $\rho \defeq \sum_{a \in \Sigma} p(a)\rho_a$ is a convex combination of density operators, then
        \begin{equation*}
            \ent(\rho) \leq \ent(p) + \sum_{a \in \Sigma} p(a) \ent(\rho_a).
        \end{equation*}
    \end{fact}
\end{solution}

\end{document}
