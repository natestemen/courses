\documentclass[
	pages,
	boxes,
	color=WildStrawberry
]{homework}


\usepackage{cleveref}
\usepackage{macros}
\usepackage{todonotes}
\usepackage{tikz-cd}
\usepackage{pythonhighlight}
\input{config}
\hwnum{4}
\duedate{Wed, Mar 10, 2020 10:00 PM}

\colorlet{Ppink}{MidnightBlue!20}
\newtcbox{\mafbox}[1][]{on line, math upper,
	boxsep=4pt, left=0pt,right=0pt,top=0pt,bottom=0pt,
	colframe=white,colback=Ppink,
	highlight math style={enhanced}
}

\begin{document}

\begin{problem}
Let $(\sigma, V)$ be a complex representation of $\slie{2}{\C}$. Define $H, X, Y$ as in p.96 of Hall. Let $v \in V \setminus \{0\}$ be an eigenvector of $\sigma(H)$ such that $\sigma(X) v = 0$, and define $v_{k} = \sigma(Y)^k v$ for $k \geq 0$. Prove that
\[
	\sigma(X)v_k = k(\lambda - k + 1)v_{k-1}, \text{ for all } k \geq 1.
\]
\end{problem}

\begin{solution}
	Let $\sigma(H)v = \lambda v$ and recall the following commutation relations:
	\begin{align*}
		\comm{X}{Y} & = H & \comm{H}{Y} & = -2Y
	\end{align*}
	Now let's calculate $\sigma(X)v_k$.
	\begin{align*}
		\sigma(X)v_k & = \sigma(X)\sigma(Y)^k v                                                                                                                                     \\
		             & = \qty[\sigma(X)\sigma(Y)]\sigma(Y)^{k-1}v                                                                                                                   \\
		             & = \qty[\sigma(H) + \sigma(Y)\sigma(X)]\sigma(Y)^{k-1}v \tag*{\tiny $\mafbox{\sigma(H) = \sigma(\comm{X}{Y}) = \sigma(X)\sigma(Y) - \sigma(Y)\sigma(X)}$}     \\
		             & \shortvdotswithin{=}
		             & = k\sigma(H)\sigma(Y)^{k-1}v + \sigma(Y)^k \underbrace{\sigma(X)v}_{0}                                                                                       \\
		             & = k\qty[\sigma(Y)\sigma(H) - 2\sigma(Y)]\sigma(Y)^{k-2}v \tag*{\tiny $\mafbox{-2\sigma(Y) = \sigma(\comm{H}{Y}) = \sigma(H)\sigma(Y) - \sigma(Y)\sigma(H)}$} \\
		             & \shortvdotswithin{=}
		             & = k\qty\Big[\sigma(Y)^{k-1}\underbrace{\sigma(H)v}_{\lambda v} - 2(k-1)\underbrace{\sigma(Y)^{k-1}v}_{v_{k-1}}]                                              \\
		             & = k\qty(\lambda - 2k + 2)v_{k-1}
	\end{align*}
	Not sure if the question is incorrect or if I missed something. I cannot see it though. I've looked through for at least 2 hours, so if you see my error \emph{please} point it out.
\end{solution}

\begin{problem}
Let $(\Pi_1, V_1)$, $(\Pi_2, V_2)$ two representations of a connected matrix Lie group. Prove that $(\Pi_1, V_1)$ is isomorphic to $(\Pi_2, V_2)$ if and only if $(\pi_1, V_1)$ is isomorphic to $(\pi_2, V_2)$, where $(\pi_1, V_1), (\pi_2, V)$ denote the associated Lie algebra representations.
\end{problem}

\begin{solution}
	Suppose $(\Pi_1, V_2)\cong (\Pi_2, V_2)$ by an intertwining map $\phi$. Then we have a commutative diagram.
	\begin{equation*}
		\begin{tikzcd}[row sep=large, column sep=large]
			V_1 \arrow{r}{\phi} \arrow[swap]{d}{\Pi_1(g)} & V_1 \arrow{d}{\Pi_2(g)} \\
			V_1 \arrow{r}{\phi} & V_2
		\end{tikzcd}
	\end{equation*}
	Since this holds for all $g\in G$ it will certainly hold for all $\e^{tX}$ with $X\in\mfr{g}$.
	\begin{align*}
		\qty[\phi\circ \Pi_1(\e^{tX})]v            & = \qty[\Pi_2(\e^{tX})\circ\phi]v             \\
		\qty[\phi\circ \e^{t\pi_1(X)}]v            & = \qty[\e^{t\pi_2(X)}\circ \phi]v            \\
		\phi\qty[\e^{t\pi_1(X)}v]                  & = \e^{t\pi_2(X)}\qty[\phi(v)]                \\
		\phi\qty[\1 v + t\pi_1(X)v + \order*{t^2}] & = \qty[\1 + t\pi_2(X) + \order*{t^2}]\phi(v) \\
		\phi(v) + t\phi(\pi_1(X)v) + \order*{t^2}  & = \phi(v) + t\pi_2(X)\phi(v) + \order*{t^2}  \\
		\phi(\pi_1(X)v)                            & = \pi_2(X)\phi(v)
	\end{align*}
	Where the last equality is obtained by cancelling $\phi(v)$ on both sides, dividing by $t$ and taking the limit $t\to 0$. This implies $\phi\circ \pi_1 = \pi_2\circ \phi$.

	To go the other way start with $\psi\circ\pi_1(X) = \pi_2(X)\circ\psi$. Any element in a connected Lie group can be written as $g = \e^{X_1}\e^{X_2}\cdots\e^{X_n}$ for some $n$ and some $X_i$'s. Now we'll show $\psi\circ \Pi_1(g) = \Pi_2(g)\circ \psi$.
	\begin{align*}
		\psi\qty[\Pi_1(\e^{X_1}\e^{X_2}\cdots\e^{X_n})] & = \psi\qty[\Pi_1(\e^{X_1})\cdots\Pi_1(\e^{X_n})]                              \\
		                                                & = \psi\qty[\e^{\pi_1(X_1)}\cdots\e^{\pi_1(X_n)}]                              \\
		                                                & = \e^{\pi_2(X_1)}\circ\psi\circ\e^{\pi_1(X_2)}\circ\cdots\circ\e^{\pi_1(X_n)} \\
		                                                & = \e^{\pi_2(X_1)}\circ\cdots\circ\e^{\pi_2(X_n)}\circ\psi                     \\
		                                                & = \Pi_2(\e^{X_1}\cdots\e^{X_n})\circ\psi
	\end{align*}
\end{solution}

\begin{problem}
Let $V$ be a real or complex representation of a matrix Lie group or Lie algebra.
\begin{parts}
	\part{Prove that the dual representation $V^*$ is irreducible if and only if $V$ is irreducible.}\label{part:3a}
	\part{Prove that $(V^*)^*$ is isomorphic to $V$ as a representation.}\label{part:3b}

	(\textit{Given a subspace $W$ of $V$, its annihilator is the subspace of $V^*$ given by
		\[
			W^{0}= \qty{l \in V^* : l(w) = 0 \,\text{ for all }w \in W}.
		\]
		Recall that $(W^{0})^{0}$ under the canonical vector space isomorphism $V \equiv (V^*)^*$, and thus $W \mapsto W^{0}$ establishes a one-to-one correspondence between subspaces of $V$ and those of $V^*$. Look up annihilators if the preceding paragraph is not a review for you.})
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:3a}
	Suppose $V^*$ is an irreducible representation, and let $W\subseteq V$ be an invariant subspace. We can then show $W^0$ is an invariant subspace of $V^*$ by the following.
	\begin{equation*}
		\qty(\Pi^*(g)l)(w) = l(\Pi(g^{-1}) w) = l(\tilde{w}) = 0
	\end{equation*}
	Where we used the fact that $G\cdot W\subseteq W$ and therefore there must exist a $\tilde{w}$ such that $\tilde{w} = \Pi(g^{-1})w$. Hence $W^0$ is an invariant subspace of $V^*$. Since $V^*$ is an irrep, $W^0 = \qty{\overline{0}}$ or $W^0 = V^*$.

	If $W^0 = V^*$ then \emph{every} linear functional annhilates every vector of $W$ which is only possible when $W = \qty{0}$ the zero vector.

	If $W^0 = \qty{\overline{0}}$ then we want to show $W = V$. We'll do this by contrapositive. So suppose $W \neq V$ is a subspace, and take $\qty{e_i}_{i = 1}^n$ is a basis for $V$ with $W$ spanned by $\qty{e_i}_{i = 1}^m$ with $m < n$. Now define the following linear functional
	\begin{equation*}
		f(v) = f\qty(\sum_{i = 1}^n\alpha_i e_i) = \sum_{i = m + 1}^n \alpha_i
	\end{equation*}
	This is clearly $\C$-linear and homogeneuous, so indeed an element of the dual space. Thus we've found a linear functional such that $f|_W \equiv 0$. This implies $W^0 \neq \qty{\overline{0}}$. Thus, by contrapositive, $W = V$.

	We've just shown $\mafbox{V^*\text{ irrep }\implies V\text{ irrep}}$, and taking the dual of both sides yields $V^{**}$ irrep $\implies V^*$ irrep. Now using the natural isomorphism of vector spaces $V^{**}\cong V$ we have $\mafbox{V\text{ irrep }\implies V^*\text{ irrep}}$.

	\ref{part:3b}
	Take the following commutative diagram:
	\begin{equation*}
		\begin{tikzcd}[row sep=large, column sep=large]
			V \arrow{r}{\psi} \arrow[swap]{d}{\Pi(g)} & V^{**} \arrow{d}{\Pi^{**}(g)} \\
			V \arrow{r}{\psi} & V^{**}
		\end{tikzcd}
	\end{equation*}
	where $\psi: V\to V^{**}$ is defined as $\psi(v)(\phi)\defeq \operatorname{ev}_v(\phi) = \phi(v)$. To show this commutes we'll have to show $\Pi^{**}(g)\circ \psi = \psi \circ \Pi(g)$. First the left hand side where $v\in V$ and $f\in V^*$.
	\begin{align*}
		\qty\Big[\qty(\Pi^{**}(g)\circ \psi)(v)](f) & = \qty\Big[\Pi^{**}(g)(\psi(v))](f)             \\
		                                            & = \qty\Big[\Pi^{**}(g)(\operatorname{ev}_v)](f) \\
		                                            & = \operatorname{ev}_v(\Pi^{*}(g^{-1})f)         \\
		                                            & = \qty\Big[\Pi^{*}(g^{-1})f](v)                 \\
		                                            & = f(\Pi(g)v)
	\end{align*}
	And now the left hand side:
	\begin{align*}
		\qty\Big[(\psi\circ \Pi(g))(v)](f) & = \psi(\Pi(g)v)(f)               \\
		                                   & = \operatorname{ev}_{\Pi(g)v}(f) \\
		                                   & = f(\Pi(g)v)
	\end{align*}

	$f$ and $v$ are completely arbitrary, so this holds for all $v\in V$ and $f\in V^{*}$. Thus $\psi$ is an intertwining map and we can use Schur's lemma to say $\psi$ is an isomorphism (since it is clearly not 0). Thus $(\Pi, V)\cong (\Pi^{**}, V^{**})$.
\end{solution}

\begin{problem}
Let $(\Pi_1, V_1), (\Pi_2, V_2)$ be representations of a matrix Lie group $G$. Denote by $\Hom(V_1, V_2)$ the space of linear transformations from $V_1$ to $V_2$. For $T \in \Hom(V_1, V_2)$ and $g \in G$, define
\[
	\Pi(g)T = \Pi_2(g) \circ T \circ \Pi_1(g^{-1}).
\]
\begin{parts}
	\part{Prove that $(\Pi, \Hom(V_1, V_2))$ is a representation of $G$.}\label{part:4a}
	\part{Prove that $(\Pi, \Hom(V_1, V_2))$ is isomorphic as a representation to $(V_1)^* \otimes V_2$.}\label{part:4b}
	\part{Prove that $T \in \Hom(V_1, V_2)$ is an intertwining map with respect to $\Pi_1, \Pi_2$ if and only if $\Pi(g)T = T$ for all $g \in G$.}\label{part:4c}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:4a}
	Here we will heavily rely on the fact that function composition is associative and we can re-bracket function composition any way we like.
	\begin{align*}
		\Pi(g_1g_2)T & \defeq \Pi_2(g_1g_2)\circ T \circ \Pi_1\qty((g_1g_2)^{-1})                                         \\
		             & = \Pi_2(g_1g_2)\circ T \circ \Pi_1\qty(g_2^{-1}g_1^{-1})                                           \\
		             & = \qty\Big(\Pi_2(g_1)\circ \Pi_2(g_2))\circ T \circ \qty\Big(\Pi_1(g_2^{-1})\circ \Pi_1(g_1^{-1})) \\
		             & = \Pi_2(g_1)\circ \qty\Big(\Pi_2(g_2)\circ T \circ \Pi_1(g_2^{-1})) \circ \Pi_1(g_1^{-1})          \\
		             & = \Pi_2(g_1)\circ \qty\Big(\Pi(g_2)T) \circ \Pi_1(g_1^{-1})                                        \\
		             & = \qty\Big(\Pi(g_1) \circ \Pi(g_2))T
	\end{align*}
	\ref{part:4b}
	Take the map $\rho: V_1^*\otimes V_2 \to \Hom(V_1, V_2)$ defined by $\rho(f\otimes v)(a) \defeq f(a)v$ where $f\in V_1^*, v\in V_2$ and $a\in V_1$. We'll now show the following diagram commutes.
	\begin{equation*}
		\begin{tikzcd}[row sep=large, column sep=large]
			V_1^*\otimes V_2 \arrow{r}{\rho} \arrow[swap]{d}{\Pi_1^*(g)\otimes \Pi_2(g)} & \Hom(V_1, V_2) \arrow{d}{\Pi(g)} \\
			V_1^*\otimes V_2 \arrow{r}{\rho} & \Hom(V_1, V_2)
		\end{tikzcd}
	\end{equation*}
	\begin{align*}
		\qty(\rho\circ \qty\Big[\Pi_1^*(g)\otimes \Pi_2(g)])(f\otimes v)(a) & = \rho\qty[\Pi^{*}_1(g)f\otimes \Pi_2(g)v](a)         \\
		                                                                    & = f(g^{-1}a)\Pi_2(g)v                                 \\
		\qty(\qty\Big[\Pi(g)\circ\rho](f\otimes v))(a)                      & = \qty\Big(\Pi_2(g)\circ f(-)v\circ \Pi_1(g^{-1}))(a) \\
		                                                                    & = \Pi_2(g)v f(g^{-1}a)
	\end{align*}
	Where I've used the notation $(\Pi^{*}_1(g)f)(a) = f(g^{-1}a)$ for convenience. Hence $\rho$ is an intertwining map.

	To show $\rho$ has an inverse let's look at the function $\tau: \Hom(V_1, V_2)\to V_1^*\otimes V_2$ defined by
	\begin{equation*}
		\tau(\varphi) = \sum_{i = 1}^{\dim V_1}e_i^*\otimes \varphi(e_i)
	\end{equation*}
	where $\qty{e_i}$ is a basis for $V_1$ and $\qty{e_i^*}$ is the corresponding dual basis. Now we'll show $\tau \circ \rho = \id_{V_1^*\otimes V_2}$ and $\rho\circ\tau = \id_{\Hom(V_1, V_2)}$.
	\begin{equation*}
		\rho(\tau(\varphi))(v) = \sum e_i^*(v)\varphi(e_i) = \varphi\qty(\sum e_i^*(v)e_i) = \varphi(v)
	\end{equation*}
	\begin{equation*}
		\tau(\rho(f\otimes v)) = \sum e_i^*\otimes \rho(f\otimes v)(e_i) = \sum e_i^*\otimes f(e_i)v = f\otimes v
	\end{equation*}
	Thus $\tau = \rho^{-1}$ and $\rho$ is an isomorphism.


	\ref{part:4c}
	Take $\Pi_1$ to be isomorphic to $\Pi_2$ with intertwining map $T$. This means the following diagram commutes for all $g\in G$.
	\begin{equation*}
		\begin{tikzcd}[row sep=large, column sep=large]
			V_1 \arrow{r}{T} \arrow[swap]{d}{\Pi_1(g)} & V_2 \arrow{d}{\Pi_2(g)} \\
			V_1 \arrow{r}{T} & V_2
		\end{tikzcd}
	\end{equation*}
	Or written as an equation we have
	\begin{equation*}
		\Pi_2(g)\circ T = T \circ \Pi_1(g)
	\end{equation*}
	Now we can compose both sides on the left with $\Pi_1(g^{-1})$.
	\begin{align*}
		\Pi_2(g)\circ T \circ \Pi_1(g^{-1}) & = T \circ \Pi_1(g) \circ \Pi_1(g^{-1}) \\
		                                    & = T \circ \Pi_1(g) \circ \Pi_1(g^{-1}) \\
		                                    & = T \circ \Pi_1(gg^{-1})               \\
		                                    & = T \circ \Pi_1(e)                     \\
		                                    & = T \circ \id_{V_1}                    \\
		                                    & = T
	\end{align*}
	This argument used all equivalences, not implications, so this shows the equivalence.
\end{solution}

\begin{problem}
Let $V$ be a finite-dimensional real or complex representation of a matrix Lie group or Lie algebra. The following are not necessarily related.
\begin{parts}
	\part{Prove that every non-trivial invariant subspace contains a non-trivial irreducible subrepresentation of $V$.}\label{part:5a}
	\part{Suppose $V$ is irreducible and complex. Consider the direct sum representation $V \oplus V$. Prove that every non-trivial invariant subspace $W$ of $V$ is isomorphic (as a representation) to $V$, and is of the form
		\[
			W = \qty{(t_1v, t_2v) : v \in V},
		\]
		for some $t_1, t_2 \in \C$ not both zero.}\label{part:5b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:5a}
	Let $W$ be the invariant subspace. When $W$ is one dimensional it's clear that itself is an irreducible subrepresentation. Now assume this is true for $\dim W = n$ and let's look at the case where $\dim W = n + 1$. Write $W = A\oplus B$ where $A$ is one dimensional and $B$ is $n$-dimensional. There are $n$ ways to do this, but one of them is guaranteed to have an irrep in $B$.

	\ref{part:5b}
	Please see the next problem to see why any irreducible subrep of $V\oplus V$ is isomorphic to $V$. To show $W$ is isomorphic to to $V$, it's clear that it's first a subspace and that $\dim W = \dim V$. By the fact that all finite dimension vector spaces of the same dimension are the same up the isomorphism it is clear that $W\cong V$.
\end{solution}

\begin{problem}
Let $V_1, V_2$ be non-isomorphic, irreducible (real or complex) representations of a matrix Lie group or Lie algebra. Consider the direct sum representation $V_1 \oplus V_2$ and regard $V_1, V_2$ as subspaces of $V_1 \oplus V_2$ in the obvious way.
\begin{parts}
	\part{Let $W$ be a non-trivial irreducible subrepresentation of $V_1 \oplus V_2$. Prove that $W = V_1$ or $V_2$.}
	\part{Prove that $V_1, V_2$ are the only non-trivial invariant subspaces of $V_1 \oplus V_2$.}
\end{parts}
\end{problem}

\begin{solution}
	We'll just do part (b) because it implies (a). Let $W$ be a a non-trivial irrep of $V_1\oplus V_2$ and let $\qty{\vb{e}_i^1}$ be a basis for $V_1$ and $\qty{\vb{e}_j^2}$ be a basis for $V_2$ such that $W$ contains some $(\vb{e}_i^1, \vb{e}_j^2)$ for some particular $i$ and $j$. By assignment 3 problem 1 we know
	\begin{equation*}
		V = \vspan_\F\qty{\Pi(A)v : A\in G}.
	\end{equation*}
	Let's apply this theorem with $v = (\vb{e}_i^1, \vb{e}_j^2)$. Thus \emph{any} irrep that contains non-zero vectors in both vector spaces must equal the entire vector space representation. That said if one of the entries in $(-,-)$ is the zero vector, then we can use the following fact
	\begin{equation*}
		\qty\big[\Pi_1\oplus\Pi_2(G)](v, 0) = (\Pi_1(G)v, 0).
	\end{equation*}
	Thus $V_1$ and $V_2$ are irreps, and indeed the only ones.
\end{solution}

\begin{problem}
Consider the representation $\mathcal{H}_m(\R^3)$ of $\SO{3}$ defined as in the previous assignment, that is, with $\Sigma: \SO{3} \to \GLV{\mathcal{H}_m(\R^3)}$ given by
\[
	\Sigma(A)f = f\circ A^{-1}.
\]
Denote the associated Lie algebra representation by $\sigma: \so{3} \to \glV{\mathcal{H}_m(\R^3)}$ and extend it to $\so{3}_{\C}$ by complex linearity. Denote the extension by $\widetilde{\sigma}$.
\begin{parts}
	\part{Prove that $\so{3}_{\C}$ is isomorphic as a complex Lie algebra to $\slie{2}{\C}$ via
		\[
			\varphi:\mqty(
			0           & 2a\iu   & \iu(b + c) \\
			-2a\iu      & 0       & c - b      \\
			-\iu(b + c) & b - c   & 0
			) \mapsto
			\mqty(
			a & b  \\
			c & -a
			).
		\]}\label{part:7a}
	\part{Consider the representation $\widetilde{\sigma} \circ \varphi^{-1}$ of $\slie{2}{\C}$. Explain how it follows from the previous assignment and what we did in lecture that $\widetilde{\sigma}\circ \varphi^{-1}$ is isomorphic to $(\pi_{2m}, V_{2m}(\C^2))$.}\label{part:7b}
	\part{Verify that $h(x, y, z) = (x + \iu y)^{m}$ is a primitive element. That is, prove that $h \in \mathcal{H}_m(\R^3)$, that it is an eigenvector of $\widetilde{\sigma}(\varphi^{-1}(H))$, and that $\widetilde{\sigma}(\varphi^{-1}(X))h = 0$.}\label{part:7c}
	\part{Introducing polar coordinates $x = r\sin s \cos t, y = r\sin s\sin t$ and $z = r\cos s$, prove that for $f \in \mathcal{H}_m(\R^3)$ we have
		\begin{align*}
			\widetilde{\sigma}(\varphi^{-1}(H))f & = -2\iu\pdv{f}{t}                                      \\
			\widetilde{\sigma}(\varphi^{-1}(X))f & = \e^{\iu t}\qty(-\iu \pdv{f}{s} + \cot(s)\pdv{f}{t})  \\
			\widetilde{\sigma}(\varphi^{-1}(Y))f & = \e^{\iu t}\qty( \iu \pdv{f}{s} + \cot(s)\pdv{f}{t}).
		\end{align*}}\label{part:7d}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:7a}
	First recall that $\so{3}_\C\cong \so{n;\,\C}$, which if $a, b, c\in\C$ is spanned by elements of the form in the problem statement above. Please take the following computer assisted proof.
	% \begin{noindent}
	\begin{python}
from sympy import Symbol, I, simplify
from sympy.matrices import Matrix
from sympy.abc import a, b, c, d, e, f

A = Matrix([
    [           0, 2 * a * I, I * (b + c)],
    [  -2 * a * I,         0,       c - b],
    [-I * (b + c),     b - c,           0]
])
B = Matrix([
    [           0, 2 * d * I, I * (e + f)],
    [  -2 * d * I,         0,       f - e],
    [-I * (e + f),     e - f,           0]
])

def varphi(mat):
    a = -I * mat[1] / 2
    b = (mat[7] - I * mat[2]) / 2
    c = (-I * mat[2] + mat[5]) / 2
    return Matrix([
        [-a, b],
        [ c, a]
    ])

simplify(varphi(A * B - B * A))\end{python}
	% \end{noindent}
	\begin{equation*}
		\left[\begin{matrix}b f - c e & - 2 a e + 2 b d\\2 a f - 2 c d & - b f + c e\end{matrix}\right]
	\end{equation*}
	% \begin{noindent}
	\begin{python}
varphi(A) * varphi(B) - varphi(B) * varphi(A)\end{python}
	%\end{noindent}
	\begin{equation*}
		\left[\begin{matrix}b f - c e & - 2 a e + 2 b d\\2 a f - 2 c d & - b f + c e\end{matrix}\right]
	\end{equation*}
	I love computers.

	\ref{part:7b}
	To show $\tilde{\sigma}\circ\varphi^{-1}$ is isomorphic to $(\pi_{2m}, V_{2m}(\C^2))$


	\ref{part:7c}
	First we show $h\in\mathcal{H}_m(\R^3)$ where $\partial_z^2 h$ is 0.
	\begin{equation*}
		\laplace{h} = \partial_x^2 h + \partial_y^2 h = m(m-1)\qty(x + \iu y)^{m-2} - m(m-1)\qty(x + \iu y)^{m-2} = 0
	\end{equation*}
	Now let's calculate $\tilde{\sigma}$ where $\vb{x} = \mqty[x & y & z]^\intercal$.
	\begin{align*}
		\tilde{\sigma}(X)f & = \eval{\dv{t}f(\e^{-tX}\vb{x})}_{t=0}                                                                      \\
		                   & = \eval{\dv{t}f(\vb{x}(t))}_{t=0}                                                                           \\
		                   & = \eval{\pdv{f}{x}\pdv{x}{t}}_{t=0} + \eval{\pdv{f}{y}\pdv{y}{t}}_{t=0} + \eval{\pdv{f}{z}\pdv{z}{t}}_{t=0}
	\end{align*}
	It's not hard to see that $\eval{\pdv{\vb{x}(t)}{t}}_{t=0} = -X\vb{x}$ and hence we have the following equations for the partials:
	\begin{align*}
		\eval{\pdv{x}{t}}_{t=0} & = -(X_{11}x + X_{12}y + X_{13}z)  \\
		\eval{\pdv{y}{t}}_{t=0} & = -(X_{21}x + X_{22}y + X_{23}z)  \\
		\eval{\pdv{z}{t}}_{t=0} & = -(X_{31}x + X_{32}y + X_{33}z).
	\end{align*}
	Now we can verify $h$ is a eigenvector of $\tilde{\sigma}(\varphi^{-1}(H))$.
	\begin{equation*}
		\tilde{\sigma}(\varphi^{-1}(H)) = \tilde{\sigma}\qty(\smqty[0    & 2\iu & 0 \\ -2\iu & 0 & 0 \\ 0 & 0 & 0]) = -2\iu y\pdv{x} + 2\iu x\pdv{y}
	\end{equation*}
	Hence
	\begin{align*}
		\tilde{\sigma}(\varphi^{-1}(H))h & = -2\iu y m(x + \iu y)^{m-1} - 2xm(x + \iu y)^{m-1} \\
		                                 & = -2m(x + \iu y)^m = h.
	\end{align*}
	And now to show $\tilde{\sigma}(\varphi^{-1}(X))h = 0$.
	\begin{align*}
		\tilde{\sigma}(\varphi^{-1}(X))h & = \qty[-\iu z\pdv{x} + z\pdv{y} + (\iu x - y)\pdv{z}]\qty(x + \iu y)^m \\
		                                 & = -\iu zm(x + \iu y)^{m-1} + \iu zm(x + \iu y)^{m-1} = 0
	\end{align*}

	\ref{part:7d}
	To do this problem one must calculate the Jacobian
	\begin{equation*}
		\pdv{(x, y, z)}{(r, s, t)}
	\end{equation*}
	and I do not have time for that today I'm afraid. Once those are calculated you can use the chain rule
	\begin{equation*}
		\pdv{x} = \pdv{r}{x}\pdv{r} + \pdv{s}{x}\pdv{s} + \pdv{t}{x}\pdv{t}
	\end{equation*}
	to calculate the partials and then it's some algebra.

	I don't understand what this problem was supposed to show us though, and how it was related to spherical harmonics.
\end{solution}

\begin{problem}
Let $\pi: \slie{3}{\C} \to \glV{V}$ be an irreducible complex representation of $\slie{3}{\C}$, and denote by $\pi^*$ the dual representation, acting on $V^*$.
\begin{parts}
	\part{Prove that the weights of $\pi^*$ are the negatives of the weights of $\pi$.}\label{part:8a}
	\part{Prove that if $\pi$ has highest weight $(m_1, m_2)$, then $\pi^*$ has highest weight $(m_2, m_1)$.}\label{part:8b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:8a}
	First recall the dual representation of a Lie algebra representation is given by
	\begin{equation*}
		\pi^*(X) = -\pi(X)^\intercal.
	\end{equation*}
	Also recall the fact that any matrix $A\in\mats{n}{\C}$ satisfies $\spectrum A = \spectrum A^\intercal$. Thus if
	\begin{equation*}
		\pi(H_1)v = m_1v \qquad \text{and} \qquad \pi(H_2)v = m_2v
	\end{equation*}
	then $m_1\in\spectrum \pi(H_1)^\intercal$ and $m_2\in\spectrum \pi(H_2)^\intercal$. Finally, accounting for the minus sign in the dual representation we have $-m_1\in\spectrum(-\pi(H_1)^\intercal) = \pi^*(H_1)$ and $-m_2\in\spectrum(-\pi(H_2)^\intercal) = \pi^*(H_2)$. Thus for any weight $(m_1, m_2)$ belonging to $\pi$, $(-m_1, -m_2)$ belongs to $\pi^*$.

	\ref{part:8b}
	Let $\mu = (m_1, m_2)$ be the highest weight of $\pi$. This means there are $a, b\geq 0$ such that for all weights $(m_1', m_2')$
	\begin{align*}
		m_1 - m_1' & = 2a - b  \\
		m_2 - m_2' & = -a + 2b
	\end{align*}
	and thus adding the two equations together we have
	\begin{equation*}
		m_1 + m_2 - (m_1' + m_2') = a + b.
	\end{equation*}
	Now take $\mu^* = (m_1^*, m_2^*) = (-\hat{m}_1, -\hat{m}_2)$ be the highest weight of $\pi^*$. This implies there exist $a', b'\geq 0$ such that for all weights $(m_1^*, m_2^*) = (-\tilde{m}_1, -\tilde{m}_2)$ such that
	\begin{align*}
		\hat{m}_1 - \tilde{m}_1' & = -2a' + b' \\
		\hat{m}_2 - \tilde{m}_2' & = a' - 2b'
	\end{align*}
	Again adding the two equations together we have
	\begin{align*}
		\hat{m}_1 + \hat{m}_2 - (\tilde{m}_1 + \tilde{m}_2) & = -(a' + b') \\
		\tilde{m}_1 + \tilde{m}_2 - (\hat{m}_1 + \hat{m}_2) & = a' + b'
	\end{align*}
	And this somehow shows $\hat{m}_1 = m_2$ and $\hat{m}_2 = m_1$. Just kidding, I'm pretty lost.

\end{solution}

\end{document}