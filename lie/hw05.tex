\documentclass[
	pages,
	boxes,
	color=WildStrawberry
]{homework}


\usepackage{cleveref}
\usepackage{macros}
\usepackage{qtree}
\usepackage{booktabs}
\input{config}
\hwnum{5}
\duedate{Wed, Mar 24, 2020 10:00 PM}

\colorlet{Ppink}{MidnightBlue!20}
\newtcbox{\mafbox}[1][]{on line, math upper,
	boxsep=4pt, left=0pt,right=0pt,top=0pt,bottom=0pt,
	colframe=white,colback=Ppink,
	highlight math style={enhanced}
}

\begin{document}

\begin{problem}
Consider the adjoint representation of $\slie{3}{\C}$ as a representation of $\slie{2}{\C}$ by restriction to the subalgebra $\mathsf{g}_1 = \vspan_{\C}\{H_1, X_1, Y_1\} \simeq \slie{2}{\C}$.
\begin{parts}
	\part{Decompose this representation as a direct sum of irreducible representations of $\slie{2}{\C}$.}\label{part:1a}
	\part{Which isomorphism types appear in the decomposition in (a), and with what multiplicity?}\label{part:1b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:1a}
	Since the wording of this question is quite confusing, it's helpful to clarify how I interpreted the question. We're working with the representation $\ad\!|_{\mathsf{g}_1}:\mathsf{g}_1\to\mathsf{gl}(\slie{3}{\C}) = \End(\slie{3}{\C})$.

	In order to understand the invariant subspaces of $\ad\!|_{\mathsf{g}_1}$ we first find the eigenvectors of $\ad_{H_1}$ that are annihilated by $\ad_{X_1}$. Indeed the commutation relations easily show we have
	\begin{align*}
		\comm{H_1}{X_1} & = 2X_2 & \comm{X_1}{X_1} & = 0 \\
		\comm{H_1}{Y_2} & = Y_2  & \comm{X_1}{Y_2} & = 0 \\
		\comm{H_1}{X_3} & = X_3  & \comm{X_1}{X_3} & = 0
	\end{align*}
	Now we can apply $\ad_{Y_1}$ to each one of these eigenvectors to better understand the invariant subspaces. I've ignored constants in the following chains for simplicity.
	\begin{align*}
		X_1 & \xrightarrow{\comm{Y_1}{X_1}} H_1 \xrightarrow{\comm{Y_1}{H_1}}Y_1 \xrightarrow{\comm{Y_1}{Y_1}} 0 \\
		Y_2 & \xrightarrow{\comm{Y_1}{Y_2}} Y_3 \xrightarrow{\comm{Y_1}{Y_3}} 0                                  \\
		X_3 & \xrightarrow{\comm{Y_1}{X_3}} X_2 \xrightarrow{\comm{Y_1}{X_2}} 0                                  \\
	\end{align*}
	Hence we have found 3 invariant subspaces.

	\ref{part:1b}
	Again here is where the wording is very confusing: are we talking about the adjoint representation as a whole, or simply the restriction? All the classmates I talked to thought it was the whole thing. I'll do the whole thing so I don't get points taken off for doing something that wasn't quite asked for, but maybe it was???

	Since the adjoint representation is 8 dimensional, and above we found 7, we need one more. Above we never got the vector $H_2$ so we'll be looking for that. Inspecting the following two commutation relations helps us spot the last:
	\begin{align*}
		\ad_{Y_1}(H_1) = 2Y_1 &  & \ad_{Y_1}(H_2) = -Y_2.
	\end{align*}
	Thus the last invariant subspace is spanned by $H_1 + 2H_2$. In sum we have
	\begin{equation*}
		(\ad, \slie{3}{\C})\cong (\pi_2, V_2(\C^2))\oplus (\pi_1, V_1(\C^2)) \oplus (\pi_1, V_1(\C^2)) \oplus (\pi_0, V_0(\C^2))
	\end{equation*}
	And so the multiplicity of 2 is 1, 1 is 2 and 0 is 1.
\end{solution}

\begin{problem}
Recall how we constructed an irreducible complex $\slie{3}{\C}$ representation with highest weight $(1, 1)$ by considering the tensor product representation $\C^3 \otimes (\C^3)^*$.
\begin{parts}
	\part{Use the same method to construct an irreducible complex $\slie{3}{\C}$-representation with highest weight $(2, 0)$, acting on a subspace of $\C^3 \otimes \C^3$.}\label{part:2a}
	\part{Determine the dimension of this representation, along with all the weights and their multiplicities. (The multiplicity of a weight is the dimension of its weight space.)}\label{part:2b}
	\part{Decompose $\C^3 \otimes \C^3$, the tensor product of two copies of the standard $\slie{3}{\C}$-representation, into a direct sum of irreducible representations.}\label{part:2c}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:2a}
	Take the product basis of $\C^3\otimes\C^3$, that is $e_i\otimes e_j$ for $i,j\in\qty{1,2,3}$. As a guess we will take $e_1\otimes e_1$ as the starting point to apply $\pi_{2,0}(Y_1)$ and $\pi_{2, 0}(Y_2)$ repeatedly. Branching left indicates $Y_1$ has been applied, and right indicates $Y_2$.

	\Tree[.$e_1\otimes e_1$ [.${e_1\otimes e_2 + e_2\otimes e_1}$
				[.${e_2\otimes e_2}$ [.0 ]
							[.${e_2\otimes e_3 + e_3\otimes e_2}$ [.0 ]
									[.${e_3\otimes e_3}$ [.0 ] [.0 ]]]]
					[.${e_1\otimes e_3 + e_3\otimes e_1}$
						[.${e_2\otimes e_3 + e_3\otimes e_2}$ ] [.0 ]]]
			[.0 ]]

	Thus we have a 6 dimensional representation spanned by the symmetric vectors of $\C^3\otimes\C^3$. We can also find the associated weights by adding together the weights of $e_i$ from the standard representation.
	\begin{table}[h]
		\centering\begin{tabular}{r c c}
			Eigenvector                       & Weight    & Multiplicity \\ \toprule
			$e_1\otimes e_1$                  & $(2, 0)$  & 1            \\
			$e_2\otimes e_2$                  & $(-2, 2)$ & 1            \\
			$e_3\otimes e_3$                  & $(0, -2)$ & 1            \\
			$e_1\otimes e_2 + e_2\otimes e_1$ & $(0, 1)$  & 1            \\
			$e_1\otimes e_3 + e_3\otimes e_1$ & $(1, -1)$ & 1            \\
			$e_2\otimes e_3 + e_3\otimes e_2$ & $(1, 0)$  & 1
		\end{tabular}
		\caption{Weights of product representation}\label{tab:prodweights}
	\end{table}
	Inspecting \cref{tab:prodweights}, and calculating $\mu_i - \mu_j = a\alpha_1 + b\alpha_2$ we can (tediously) verify that $(2, 0)$ is indeed the highest weight.


	\ref{part:2b}
	Refer to \cref{tab:prodweights}.

	\ref{part:2c}
	Since the above representation is 6 dimensional, and $\C^3\otimes \C^3$ is 9 dimensional, we need to try and find a representation that lives on the other 3 dimensions. First, note that the ``other'' 3 dimensions are spanned by
	\begin{align*}
		e_2\otimes e_1 - e_1\otimes e_2 &  & e_3\otimes e_1 - e_1\otimes e_3 &  & e_3\otimes e_2 - e_2\otimes e_3
	\end{align*}
	which are the antisymmetric subspace of $\C^3\otimes \C^3$.\footnote{I wish we learned about symmetric and anti-symmetric powers of vector spaces in this class, because I see them mentioned all over the place when reading material about decomposing representations.} To find what this representation looks like we can again apply $\pi_{2, 0}(Y_i)$ with the same convention as above.

	\Tree[.${e_1\otimes e_2 - e_2\otimes e_1}$ [.0 ] [.${e_3\otimes e_1 - e_1\otimes e_3}$ [.${e_3\otimes e_2 - e_2\otimes e_3}$ [.0 ] [.0 ]] [.0 ]]]

	This tree is exactly that of the standard representation acting on $e_1, e_2, e_3$, and hence we conclude that we have one copy of the standard representation. In final, we have
	\begin{equation*}
		(\pi_{2, 0}, \C^3\otimes \C^3)\cong (\pi_{1, 0}\otimes\pi_{1, 0}, \Sym^2(\C^3))\oplus (\pi_{1, 0}, \C^3).
	\end{equation*}
	Although I'm wondering if that last factor should be $(\pi_{1, 0}, \bigwedge^2(\C^3))$? I guess they're isomorphic, so maybe it doesn't matter? Would be good to know.
\end{solution}

\begin{problem}
Let $V_{m}(\C^3) = \vspan_{\C}\qty{z_1^k\, z_2^l\, z_3^{m - k - l} : 0 \leq k + l \leq m}$ and define $(\Pi_m(A)f)(z) = f(A^{-1}z)$ for $A \in \SU{3}$ and $f \in V_m(\C^3)$.
\begin{parts}
	\part{Prove that $(\Pi_m, V_m(\C^3))$ is a complex representation of $\SU{3}$.}\label{part:3a}
	\part{Find the weights for $\pi_1$ and $\pi_2$, the $\slie{3}{\C}$-representations associated to $\Pi_1$ and $\Pi_2$, respectively.}\label{part:3b}
	\part{Prove that $(\pi_1, V_1(\C^3))$ and $(\pi_2, V_2(\C^3))$ are irreducible representations of $\slie{3}{\C}$. What are their highest weights?}\label{part:3c}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:3a}
	\begin{equation*}
		\Pi_m(A)\qty(\qty\Big[\Pi_m(B)f])(z) = \qty\Big[\Pi_m(B)f](A^{-1}z) = f(B^{-1}A^{-1}z) = \qty\Big[\Pi_m(AB)f](z)
	\end{equation*}

	\ref{part:3b}
	The action of an arbitrary element $X\in\slie{3}{\C}$ under the representation $\pi_m$ is given by
	\begin{align*}
		\pi_m(X) & = -\qty(X_{11} z_1 + X_{12}z_2 + X_{13}z_3)\pdv{z_1}    \\
		         & \quad -\qty(X_{21}z_1 + X_{22}z_2 + X_{23}z_3)\pdv{z_2} \\
		         & \quad -\qty(X_{31}z_1 + X_{32}z_2 + X_{33}x_3)\pdv{z_3}
	\end{align*}
	Thus, for $H_1$ and $H_2$ we have
	\begin{align*}
		\pi_m(H_1) & = z_2\pdv{z_2} - z_1\pdv{z_1} \\
		\pi_m(H_2) & = z_3\pdv{z_3} - z_2\pdv{z_2}
	\end{align*}

	Take $m = 1$ where $V_1 = \vspan_\C\qty{z_1, z_2, z_3}$. Applying $\pi_1(H_1)$ and $\pi_1(H_2)$ to an arbitrary element $f = az_1 + bz_2 + cz_3$ and ensuring it is an eigenvector yields the following two equations:
	\begin{align*}
		(m_1 + 1)az_1 + (m_1 - 1)bz_2 + cm_1z_3 & = 0 \\
		m_2az_1 + (m_2 + 1)bz_2 + (m_2 - 1)cz_3 & = 0
	\end{align*}
	From here we can see there are three weights possible tabulated in \cref{tab:pione}.
	\begin{table}[h]
		\centering\begin{tabular}{c c c}
			Weight    & Eigenvector & Multiplicity \\ \toprule
			$(1, -1)$ & $bz_2$      & 1            \\
			$(-1, 0)$ & $az_1$      & 1            \\
			$(0, 1)$  & $cz_3$      & 1
		\end{tabular}
		\caption{Weight Decomposition for $(\pi_1, V_1(\C^3))$}\label{tab:pione}
	\end{table}

	Take $m = 2$ where $V_2 = \vspan_\C\qty{z_1^2, z_2^2, z_3^2, z_1z_1, z_1z_3, z_2z_3}$ and we can repeat the process as above with an arbitrary element $f = az_1^2 + bz_2^2 + cz_3^2 + dz_1z_2 + ez_1z_3 + gz_2z_3$.
	\begin{align*}
		\pi_2(H_1)f & = -2az_1^2 + 2bz_2^2 - ez_1z_3 + gz_2z_3 \\
		\pi_2(H_2)f & = -2bz_2^2 + 2cz_3^2 - dz_1z_d + ez_1z_3
	\end{align*}
	From here we can read off the weights and eigenvectors, probably much easier than the equation I wrote down for the $m = 1$ case.
	\begin{table}[h]
		\centering\begin{tabular}{c c c}
			Weight    & Eigenvector & Multiplicity \\ \toprule
			$(-2, 0)$ & $az_1^2$    & 1            \\
			$(-2, 2)$ & $bz_2^2$    & 1            \\
			$(0, 2)$  & $cz_3^2$    & 1            \\
			$(0, -1)$ & $dz_1z_1$   & 1            \\
			$(-1, 0)$ & $ez_1z_3$   & 1            \\
			$(1, 0)$  & $gz_2z_3$   & 1
		\end{tabular}
		\caption{Weight Decomposition for $(\pi_2, V_2(\C^3))$}\label{tab:pitwo}
	\end{table}

	\ref{part:3c}
	To show $(\pi_1, V_1(\C^3))$ and $(\pi_2, V_2(\C^3))$ are irreps we will first show they are highest weight cyclic representations. Then using Proposition 6.14 from Hall, and the fact that all representations of $\slie{3}{\C}$ are completely reducible, we can deduce that the aforementioned representations are irreducible.

	For the $m = 1$ case we have highest weight vector $v = cz_3$ with weight $(0, 1)$. This is easily verified (although tedious) by computing $\mu_i - \mu_j = a\alpha_1 + b\alpha_2$ for the weights in \cref{tab:pione}. Thus condition 1 is satisfied. Now we can apply each $X_i$ to $v$ to see if it's annihilated.
	\begin{align*}
		\pi_1(X_1)v & = -z_2\pdv{z_1}\qty(cz_3) = 0 \\
		\pi_1(X_2)v & = -z_3\pdv{z_2}\qty(cz_3) = 0 \\
		\pi_1(X_2)v & = -z_3\pdv{z_1}\qty(cz_3) = 0
	\end{align*}
	Thus we also have condition two that $\pi_1(X_i)v = 0$. Lastly we have to verify $V_1(\C^3)$ is the smallest invariant subspace that contains $v$. We can do this by creating the ``tree'' applying all $\pi_1(Y_i)$. We use the convention of ``left'' means apply $\pi_1(Y_1)$, ``center'' means $\pi_1(Y_2)$ and ``right'' means $\pi_1(Y_3)$.

	\Tree[.$z_3$ [.0 ]
			[.$z_2$ [.$z_1$ ]
					[.0 ]
					[.0 ]]
			[.$z_1$ [.0 ]
					[.0 ]
					[.0 ]]]

	This diagram shows there no invariant subspace containing $v$ that is not the entirety of $V_1(\C^3)$. Thus $(\pi_1, V_1(\C^3))$ is a cyclic representation with highest weight $(0, 1)$ and by the argument given at the outset of~\ref{part:3c} we have an irrep.

	Now take $m = 2$ and we will run through the same process. The highest weight in \cref{tab:pitwo} is $(0, 2)$ again by (tediously) computing $\mu_i - \mu_j = a\alpha_1 + b\alpha_2$ repeatedly. We can now check if $v = cz_3^2$ is annihilated by all $\pi_2(X_i)$.
	\begin{align*}
		\pi_2(X_1)v & = -z_2\pdv{z_1}\qty(cz_3^2) = 0 \\
		\pi_2(X_2)v & = -z_3\pdv{z_2}\qty(cz_3^2) = 0 \\
		\pi_2(X_2)v & = -z_3\pdv{z_1}\qty(cz_3^2) = 0
	\end{align*}
	And again now we need to check if there is a smaller invariant subspace containing $v$.

	\Tree[.$z_3^2$ [.0 ]
			[.$z_2z_3$ [.$z_1z_3$ [.0 ] [.$z_1z_2$ ] [.$z_1^2$ [.0 ] [.0 ] [.0 ]]]
					[.$z_2^2$ [.$z_1z_2$ ] [.0 ] [.0 ]]
					[.$z_1z_2$ ]]
			[.$z_1z_3$ [.0 ]
					[.$z_1z_2$ [.$z_1^2$ ] [.0 ] [.0 ]]
					[.$z_1z_3$ ]]]

	So indeed this representation is highest weight cyclic with weight $(0, 2)$ and is thus irreducible by the above logic.
\end{solution}

\begin{problem}
In each part below, verify that $\mfr{t}$ is a Cartan subalgebra of $\mfr{g} = \operatorname{Lie}(G)$. Then find the maximal torus in $G$ corresponding to $\mfr{t}$.
\begin{parts}
	\part{$G = \SO{2n}$; $\mfr{t} = \qty{ \smqty(0 & \theta_1 & & & \\ -\theta_1 & 0 & & & \\ & & \ddots &  & \\  & & & 0 & \theta_n\\ & & & -\theta_n & 0) : \theta_i \in \R }$.}\label{part:4a}
	\part{$G = \SO{2n + 1}$; $\mfr{t} = \qty{ \smqty(0 & \theta_1 & & & & \\ -\theta_1 & 0 & & & & \\ & & \ddots & & &  \\ & & & 0 & \theta_n & \\ & & & -\theta_n & 0 & \\ & & & & & 0 ) : \theta_i \in \R }$.}\label{part:4b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:4a}
	First lets verify $\mfr{t}$ is indeed a Cartan subalgebra. The Lie algebra $\so{2n}$ consists of $2n\times 2n$ skew-symmetric matrices, which clearly $\mfr{t}$ is a subset of. In order to show it's a subalgebra, it must be closed under the commutator, but because this is a \emph{Cartan} subalgebra we have the extra condition that $\comm{X}{Y} = 0$ for all $X, Y\in \mfr{t}$. We'll write elements in $\mfr{t}$ in block form using $R_\alpha = \smqty[0 & \alpha \\ -\alpha & 0]$.
	\begin{align*}
		\comm{\mqty(\dmat{R_{\theta_1}, \ddots, R_{\theta_n}})}{\mqty(\dmat{R_{\phi_1}, \ddots, R_{\phi_n}})} & = \smqty(\dmat{R_{\theta_1}R_{\phi_1} - R_{\phi_1}R_{\theta_1}, \ddots, R_{\theta_n}R_{\phi_n} - R_{\phi_n}R_{\theta_n}})
	\end{align*}
	Now to calculate the terms on the diagonal:
	\begin{align*}
		R_{\theta_i}R_{\phi_i} - R_{\phi_i}R_{\theta_i} & = \mqty(0               & \theta_i \\ -\theta_i & 0 )\mqty(0 & \phi_i \\ -\phi_i & 0) - \mqty(0 & \phi_i \\ -\phi_i & 0 )\mqty(0 & \theta_i \\ -\theta_i & 0) \\
		                                                & = \mqty(-\theta_i\phi_i & 0        \\ 0 & -\theta_i\phi_i) - \mqty(-\theta_i\phi_i & 0 \\ 0 & -\theta_i\phi_i) \\
		                                                & = \mqty(0               & 0        \\ 0 & 0)
	\end{align*}
	Thus everything in $\mfr{t}$ commutes, and is also closed under the bracket/commutator since the zero matrix is skew symmetric.

	Now we must show that anything that commutes with \emph{every} element of $\mfr{t}$ is also in $\mfr{t}$. That is suppose we have some $X\in\so{2n}$ such that $\comm{X}{\mfr{t}} = 0$. Writing things out in coordinates for $C = XA$ and $D = AX$ we have
	\begin{align*}
		C_{ij} & = \sum_{k = 1}^{2n}X_{ik}A_{kj} = X_{i,j + 1}A_{j + 1, j} = -\theta_j X_{i, j + 1} \\
		D_{ij} & = \sum_{k = 1}^{2n}A_{ik}X_{kj} = A_{i, i + 1}X_{i + 1,j} = \theta_j X_{i + 1, j}
	\end{align*}
	And these must be equal, so we have
	\begin{equation}\label{eq:antisym}
		\theta_i X_{i +1, j} + \theta_j X_{i, j + 1} = 0.
	\end{equation}
	When $i = j$ then $X_{i+1, i} + X_{i, i+1} = 0$, which $A$ also satisfies. Since~\cref{eq:antisym} must be satisfied for all $X\in\mfr{t}$, it must be satisfied for $X$ such that $\theta_i = 0$ for all $i\in\Z_n$ except for one $j$ where $\theta_j = 1$. Plugging these into~\cref{eq:antisym} we see $X_{i, j+1} = 0$ for all $i\neq j$. This, combined with the fact that $X\in\so{2n}$ is anti-symmetric shows that $X\in\mfr{t}$.

	Now let's compute the maximal torus corresponding to $\mfr{t}$. It'll be helpful to compute the first few powers of an element of $\mfr{t}$ to get a sense of what's going on.
	\begin{align*}
		A^2 & = \mqty(0 & \theta_1 &  &  & \\ -\theta_1 & 0 & & & \\ & & \ddots &  & \\  & & & 0 & \theta_n\\ & & & -\theta_n & 0)^{\!\!\!2} = \mqty(-\theta_1^1 & & & & \\ & -\theta_1^2 & & & \\ & & \ddots & & \\ & & & -\theta_n^2 & \\ & & & & -\theta_n^2) \\
		A^3 & = \mqty(0 & \theta_1 &  &  & \\ -\theta_1 & 0 & & & \\ & & \ddots &  & \\  & & & 0 & \theta_n\\ & & & -\theta_n & 0)^{\!\!\!3} = \mqty(0 & -\theta_1^3 & & & \\ \theta_1^3 & 0 & & & \\ & & \ddots & & \\ & & & 0 & -\theta_n^3 \\ & & & \theta_n^3 & 0)
	\end{align*}
	These give a pretty good hint what the next terms are. Hence we can write
	\begin{align*}
		\e^{A} & = \1 + A + A^2 + A^3 + \cdots                                                                       \\
		       & = \mqty(1 - \theta_1^2 + \theta_1^4 + \cdots & \theta_1 - \theta_1^3 + \theta_1^5 - \cdots &        \\ -\theta_1 + \theta_1^3 - \theta_1^5 + \cdots & 1 - \theta_1^2 + \theta_1^4 + \cdots & \\ & & \ddots) \\
		       & = \mqty(\cos\theta_1                         & \sin\theta_1                                &   &  & \\ -\sin\theta_1 & \cos\theta_1 & & \\ & & \ddots & & \\ & & & \cos\theta_n & \sin\theta_n \\ & & & -\sin\theta_n & \cos\theta_n)
	\end{align*}
	Thus maximal torus in $\SO{2n}$ is (up to isomorphism) $\diag(R_{\theta_1},\ldots,R_{\theta_n})$ where $R_\alpha = \smqty[\phantom{-}\cos\alpha & \sin\alpha \\ -\sin\alpha & \cos\alpha]$.

	\ref{part:4b}
	The computations performed above are idential for this case, where there is an additional row and column of 0's to work with. Thus the maximal torus of $\SO{2n + 1}$ is  $\diag(R_{\theta_1},\ldots,R_{\theta_n}, \1_{2\times 2})$ which is easily seen to be isomorphic to that of $\SO{2n}$. The $\1_{2\times 2}$ arises from the first term of $\e^{A} = \1 + \cdots$.
\end{solution}


\begin{problem}
\begin{parts}
	\part{Let $n \geq 3$ and let $H$ be the set of diagonal matrices in $\SO{n}$. Prove that $H$ is a maximal closed abelian subgroup of $\SO{n}$, but is not contained in any maximal torus.}\label{part:5a}
	\part{By contrast, let $H$ be any closed abelian subgroup of $\SU{n}$. Prove that $H$ is contained in a maximal torus.}\label{part:5b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:5a}
	Note that $H$ is the the collection of matrices of the form $\diag(\pm 1, \ldots, \pm 1)$ with an even number of $-1$'s on the diagonal. This can be seen from the maximal torus of $\SO{n}$ shown in the previous problem.

	First we need to show $H$ is a maximal abelian subgroup of $\SO{n}$. Suppose $A\in\SO{n}$ commutes with all $B\in H$. We can write $A$ in canonical form as
	\begin{equation*}
		A = \diag(R_1,\ldots, R_k, \pm 1, \ldots, \pm 1)
	\end{equation*}
	where there are an even number of $-1$'s and 0's everywhere else. Using the fact that commuting matrices preserve each others' eigenspaces we see $A$ must preserve the eigenspaces of $B$. Since every standard basis vector $\vb{e}_i\in\R^n$ is an eigenvector of $B$, $A$ must map each $A\vb{e}_i = \lambda_i\vb{e}_i$. Thus all the $2\times 2$ block matrices must be plus or minus 1's. Thus $B\in H$.

	\ref{part:5b}
	Since all $X, Y\in H$ commute, they can be simultaneously diagonalized in some basis. The eigenvalues of a unitary matrix are all unit complex numbers, and hence any element in $H$ can be written as
	\begin{equation*}
		X = \diag(\e^{\iu\alpha_1},\ldots, \e^{\iu\alpha_n}).
	\end{equation*}
	Since the determinant of $X$ is 1, we have the condition that $\prod_i\e^{\iu\alpha_i} = 1$ which restricts one\footnote{And can be made to be the last.} $\alpha_i$ so we have
	\begin{equation*}
		X = \diag(\e^{\iu\alpha_1},\ldots, \e^{-\iu \sum_{i = 1}^{n-1}\alpha_i}).
	\end{equation*}
	So every $X\in H$ can be specified by $n-1$ unit complex numbers. Thus $H$ is clearly contained in the maximal torus of $\SU{n}$.
\end{solution}

\begin{problem}
Let $T$ be the set of diagonal matrices in $\U{n}$ and $W$ its Weyl group. Let $S_n$ be the permutation group of $\qty{1, \ldots, n}$ and define an action of $S_n$ on $T$ by
\[
	\sigma \cdot' \diag(u_1, \ldots, u_n) = \diag(u_{\sigma^{-1}(1)}, \ldots, u_{\sigma^{-1}(n)}).
\]
(Here we put a prime in the notation to distinguish this action from the action of $W$ on $T$.) Also, take a generating element $t_0 = \diag(\e^{2\pi\iu \theta_1}, \ldots, \e^{2\pi\iu \theta_n})$ in $T$.
\begin{parts}
	\part{Given $w \in W$, prove that there exists a unique $\sigma \in S_n$ such that
		\[
			w \cdot t_0 = \sigma \cdot' t_0.
		\]
		Deduce that $w \cdot t = \sigma \cdot' t$ for all $t \in T$.}\label{part:6a}
	\part{In the notation of part (a), prove that the map $w \mapsto \sigma$ defines an injective homomorphism from $W$ into $S_n$.}\label{part:6b}
	\part{Prove that the homomorphism in part (b) is also surjective. (Consequently, $W$ is isomorphic to $S_n$.)}\label{part:6c}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:6a}
	We have $w\cdot t_0 = xt_0x^{-1} = t'\in T$ and because $t$ and $t'$ only differ by conjugation, they must have the same spectrum, however it's possibly ``rearranged''. This can clearly be done by $\sigma\cdot't_0$, but we need to show it's unique. Suppose we have $\sigma, \tilde{\sigma}\in S_n$ such that $w\cdot t_0 = \sigma\cdot't_0 = \tilde{\sigma}\cdot't_0$. Thus we have
	\begin{equation*}
		\diag(\e^{2\pi\iu\theta_{\sigma^{-1}(1)}}, \ldots, \e^{2\pi\iu\theta_{\sigma^{-1}(n)}}) = \diag(\e^{2\pi\iu\theta_{\tilde{\sigma}^{-1}(1)}}, \ldots, \e^{2\pi\iu\theta_{\tilde{\sigma}^{-1}(n)}})
	\end{equation*}
	and these must be componentwise equal so
	\begin{equation*}
		\e^{2\pi\iu\theta_{\sigma^{-1}(i)}} = \e^{2\pi\iu\theta_{\tilde{\sigma}^{-1}(i)}}.
	\end{equation*}
	This implies $\theta_{\sigma^{-1}(i)} = \theta_{\tilde{\sigma}^{-1}(i)} + n$ for some $n\in \Z$, but by the linear independence\footnote{over $\Q$} of $1$ and the $\theta_i$'s, this is only possible if $\sigma^{-1} = \tilde{\sigma}^{-1}$ and thus $n = 0$, and by the bijectivity of elements in $S_n$, $\sigma = \tilde{\sigma}$.

	Since $t_0$ generates, we can always write $t = \lim_{n\to\infty}t_0^{a_n}$ for some subsequence $a_n$ of $\Z$. We then have
	\begin{equation*}
		w\cdot t = x\qty[\lim_{n\to\infty}t_0^{a_n}]x^{-1} = \lim_{n\to\infty}xt_0^{a_n}x^{-1} = \lim_{n\to\infty}\qty[\sigma\cdot't_0]^n = \sigma\cdot' t
	\end{equation*}

	\ref{part:6b}
	Let $f: W\to S_n$ be the map such that $w\mapsto \sigma$.
	This map is indeed a homomorphism:
	\begin{equation*}
		(w_1w_2)\cdot t = x_1x_2tx_2^{-1}x_1^{-1} = x_2(\sigma_2\cdot't)x_2^{-1} = (\sigma_1\circ \sigma_2)\cdot't
	\end{equation*}
	To show this map is an injection, suppose $w_1\mapsto \sigma$ and $w_2\mapsto\sigma$, that is $f(w_1) = f(w_2)$, where they can only be seen as equal if they are equal on all inputs.
	\begin{align*}
		f(w_1)\cdot't      & = f(w_2)\cdot't      \\
		\sigma\cdot't      & = \sigma\cdot't      \\
		x_1tx_1^{-1}       & = x_2tx_2^{-1}       \\
		\qty(x_2^{-1}x_1)t & = t\qty(x_2^{-1}x_1)
	\end{align*}
	Thus $x_2^{-1}x_1$ commutes with all $t$, and hence is in $T$. This implies $x_2^{-1}x_1$ is modded out of the Weyl group and equals the identity in $W$. Hence $w_1 = w_2$.

	\ref{part:6c}
	To see that $f$ is surjective, note that we can construct a basis change that swaps any basis vectors around in an element $x$ which we conjugate by in $w\cdot t$. Since there are $n!$ ways to swap around basis vectors, we can surely hit every element of $S_n$.\footnote{I know this is sloppy, but I'm \emph{tired}, and I'm not sure what it is, but the Weyl group doesn't \emph{feel} cool.}
\end{solution}

\begin{problem}
Let $G$ be a compact connected matrix Lie group.
\begin{parts}
	\part{Let $f: G \to H$ be a surjective Lie group homomorphism from $G$ onto another compact connected matrix Lie group. Prove that if $T$ is a maximal torus in $G$ then $f(T)$ is a maximal torus in $H$. Deduce that if $H$ is abelian then the restriction $f|_{T}$ is surjective already.}\label{part:8a}
	\part{Given $g \in G$ and $n \in \N$, prove that there exists $h \in G$ such that $h^n = g$.}\label{part:8b}
\end{parts}
\end{problem}

\begin{solution}
	\ref{part:8a}
	Since $T$ is connected and compact, and $f$ is a continuous function, $f(T)$ is also connected and compact. Since $f$ is a homomorphism we have $f(a)f(b) = f(ab) = f(ba) = f(b)f(a)$ if $a, b\in T$, and thus $f(T)$ is also commutative and by Theorem 11.2 in Hall, $f(T)$ is a torus.

	To show $f(T)$ is maximal in $H$, take $K\subseteq H$ to be a torus containing $f(T)$. Take an element $h\in K$, and by the surjectivity of $f$ we are guaranteed to be able to find a $g\in G$ such that $f(g) = h$. Since we can write $g = xtx^{-1}$ by Lemma 11.12 in Hall, we have
	\begin{equation*}
		h = f(g) = f(xtx^{-1}) = \underbrace{f(x)}_{\in H}\underbrace{f(t)}_{\in f(T)}f(x)^{-1}.
	\end{equation*}
	That is, any element $h\in K$ can be decomposed as $h = f(x)f(t)f(x)^{-1}$ which implies $K = yf(T)y^{-1}$, and thus $f(T)$ is maximal.

	\ref{part:8b}
	Since $G$ is compact and connected, we know exp: $\mathsf{g}\to G$ is surjective, and hence for all $g\in G$ we can fine an $A\in\mathsf{g}$ such that $g = \e^{A}$. In particular we can also define $h\defeq \e^{A/n}$ so that $h^n = g$.
\end{solution}

\end{document}